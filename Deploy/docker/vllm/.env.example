# Deploy/docker/vllm/.env.example
# Copy to .env and customize

# HuggingFace token (required for gated models)
HF_TOKEN=your_hf_token_here

# GPU Configuration
# GPU 0: RTX 2000 Ada (8GB), GPU 1: RTX 5060 Ti (16GB)
CUDA_VISIBLE_DEVICES=0,1

# vLLM Settings
GPU_MEMORY_UTILIZATION=0.85
MAX_MODEL_LEN=4096
TENSOR_PARALLEL_SIZE=2

# Container Resources
CONTAINER_MEMORY_LIMIT=24g
SHM_SIZE=8g

# Logging
VLLM_LOGGING_LEVEL=INFO
